<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yawn Detection by Devesh Datwani</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+HK:wght@300&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@600&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville&display=swap" rel="stylesheet">
</head>
<style>
    h4{
        color: gray;
        text-align: center;
    }
    .wrapper{
        font-family: 'Noto Sans HK', cursive;
        text-align: justify;
        margin-top: 0;
    }
    h2{
        font-family: 'Noto Sans HK', cursive;
    }
</style>
<body>
    <header>
        <a href="index.html"><h1 style="font-family: 'Libre Baskerville', serif; margin-left: 2rem; font-size: 1.5rem; color: white;"> Devesh Datwani</h1></a>
    </header>
    <h2 style="text-align: center; margin-top: 2rem;">Yawn Detection Using OpenCV</h2>
        <br><br><br><br>
        <div class="wrapper">
            <h4 style="color: black; text-align: left;">Github</h4>
            <p>https://github.com/deveshdatwani/trendsonthemap</p>
            <br>
            <h3>Introduction</h3>
            <hr>
            <br>
            <p>Yawn can be an indicator of high fatigue levels. An application that detects if a person is yawning could be deployed at various platforms.</p>
            <br>
            <h3>Theory</h3>
            <hr>
            <br>
            <p>This Python program uses the dlib library to detect shapes. The shape predictor algorithm implemented in the dlib library comes from Kazemi and Sullivanâ€™s 2014 CVPR paper, One Millisecond Face Alignment with an Ensemble of Regression Trees. Feel free to read more about it.</p>
            <br>
            <p>The "shape_predictor_68_face_landmarks" is a pretained face detector that detects 68 landmark points on a face. They are numbered as shown below.</p>
            <br>
            <div style="text-align: center;"><img src="images/facemap.png" alt="" style="width: 100%; height: auto;"><p>Image from OpenCV Docs</p></div>
            <br>
            <p>To detect if a person is yawning or not, we need to determine if the upper and lower lips are seperated by decent amount of pixels for a sufficient amount of time. A yawn generally lasts 2-3 seconds. This could give us the different between yawns and yelling/talking. We can further train a Neural Network with labelled images. But this project doesn't go into that.</p>
            <br>
            <p>The following code block shows the most important part of tha application. Rest everything is pretty standard.</p>
            <br>
            <div style="text-align: center;"><img src="images/yawn-decision.PNG" alt="" style="height: auto; width: auto;"></div>
            <br>
            <h3>Technologies Used</h3>
            <hr>
            <br>
            <ul style="margin-left: 30px;">
                <li>Python</li>
                <li>DLIB</li>
                <li>OpenCV</li>
            </ul>
            <br>
            <h3>Installation and Launch (Linux)</h3>
            <hr>
            <br>
            <p>Clone the git repository using the following command <span style="background-color: lightgray;">git clone https://github.com/deveshdatwani/Yawn-Detection.git</span></p>
            <br>
            <p>Run the yawn_detection.py script using <span style="background-color: lightgray;">python3 Yawn_Detect.py</span></p>
            <br>
            <h3>Project Walkthrough</h3>
            <hr>
            <br>
            <p>Pretty strightforward stuff here. The face-landmarks xml file is loaded in our shape predicor.</p>
            <br>
            <div style="text-align: center;"><img src="images/loading-face-landmarks.PNG" alt="" style="height: auto; width: auto;"></div>
            <br>
            <p>With reference to the landmark image above, we select landmarks of the upper and the lower lip. The average pixel height is calculated from both upper and lower lips. If the difference of these exceed a certain value (as explained in the theory), the person is said to be yawning.</p>
            <br>
            <p>Rest is pretty straightforward, I've added the comments to help understand better.</p>
        </div>
    <br><br><br>
</body>
<footer>
</footer>
</html>
